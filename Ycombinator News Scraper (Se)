from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import requests
from bs4 import BeautifulSoup
import time

driverOptions = webdriver.ChromeOptions()

def createWebdriver():
    return webdriver.Chrome(options=driverOptions)

try:
    browser = createWebdriver()
    browser.get("https://news.ycombinator.com/newest")

    wait = WebDriverWait(browser, 10)
    articles = wait.until(EC.presence_of_all_elements_located((By.XPATH, "//tr[@class='athing submission']/td[@class='title']/span[@class='titleline']/a")))
    articleInfo = []

    for article in articles:
        articleName = article.text
        link = article.get_attribute("href")
        try:
            page = requests.get(link, timeout=5)
            content = BeautifulSoup(page.text, "html.parser")
            content = content.find_all("p")
            content = "\n".join([p.get_text(strip=True) for p in content])
            articleInfo.append(f"{articleName}: {content[:20]}")
            time.sleep(1)
        except:
            print("Article not currently available")

    time.sleep(1)
    
except:
    print("Error")

finally:
    input("Press enter to quit...")
    browser.quit()
    print(articleInfo)

